<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# Common Complaints about Notion AI, Google NotebookLM, and Document‑Based AI Tools (2024–2025)

The same themes come up again and again across Notion AI, Google NotebookLM, and other “chat with your notes/docs” tools: **performance and limits, weak structure/editing, hallucinations and trust, poor interoperability, steep learning curves, and serious privacy/consent concerns**.[^1_1][^1_2][^1_3][^1_4][^1_5][^1_6][^1_7][^1_8][^1_9][^1_10]

Below is a breakdown by product, then cross‑cutting issues that show up in most document‑centric AI tools.

***

## 1. Notion AI – Most Common Complaints

### 1.1 Performance, lag, and “AI bloat”

Power users frequently complain that Notion becomes **slow and sluggish**, especially as workspaces and databases grow, and that adding AI has made it worse instead of better.[^1_11][^1_12][^1_13][^1_14]

Typical issues mentioned:

- Noticeable **lag with large databases** and complex pages.[^1_12][^1_13][^1_14]
- Perception that Notion is **prioritizing AI features over core performance and basic UX**, frustrating long‑time users who wanted speed and reliability first.[^1_15][^1_11]
- Some users explicitly report that removing or disabling AI noticeably **improves performance**.[^1_16][^1_15]


### 1.2 Steep learning curve and added complexity

Notion already had a reputation for a **steep learning curve** and “build‑it‑yourself” complexity. Adding AI:[^1_13][^1_14][^1_12]

- Makes the product feel **more complex to master**, especially for non‑technical or non‑tinkerer users.[^1_5][^1_14][^1_12]
- Overwhelms some users with overlapping features (databases, templates, relations, formulas, AI prompts) before they understand the basics.[^1_12][^1_13]


### 1.3 AI quality: mediocre compared to standalone LLMs

Users commonly say that **Notion AI feels weaker than using ChatGPT directly**:

- Reports that the **free ChatGPT model often gives better summaries or rewrites** on the same text than Notion AI.[^1_16]
- Complaints that Notion AI **freezes or crashes on long contexts**, cutting off useful conversations when trying to modify or refactor large pages.[^1_16]
- Perception that Notion AI is **“just a wrapper”** over a generic model, with limited tuning or control over which model is used.[^1_5][^1_16]


### 1.4 Limited ability to work deeply with structured data

A recurring frustration is that Notion AI **does not fully understand or operate on Notion’s own advanced structures**:

- Users point out that Notion AI **cannot directly edit or properly “see” databases**, often being limited to interacting with individual pages rather than the database as a whole.[^1_16]
- Complaints that AI cannot create sub‑pages or reorganize a large workspace in a structured way, which limits its value for serious knowledge‑management workflows.[^1_16]

In other words, it’s good at generating or cleaning up prose blocks, but weak as a **true “AI over your whole workspace”**.

### 1.5 Cost vs value

Several reviews flag **cost** as a drawback:

- AI is an **add‑on cost** on top of the main Notion subscription; reviewers note this may be prohibitive for individuals and small teams given its limitations.[^1_14][^1_5]
- Some users feel the AI **does not justify the recurring fee** relative to using cheaper or free standalone LLMs with copy‑paste.[^1_5][^1_16]


### 1.6 Editor ergonomics and “web‑editor” feel

Even apart from AI, long‑time users complain that **basic text editing is still clunky**:

- Reports of **annoying automatic formatting**, fragile list behavior, and awkward text selection due to the block‑based model.[^1_15]
- Some describe it as feeling like **“working with a bad web editor”** rather than a smooth writing tool.[^1_15]

There is resentment that Notion invested heavily in AI while the **core writing/editing experience still feels rough** to many power users.[^1_11][^1_15]

### 1.7 Offline, mobile, and basic UX limitations

Common friction points that matter a lot in real workflows:

- **Limited offline support**; offline behavior is inconsistent and not as robust as competing tools.[^1_13]
- **Mobile app limitations**: the mobile experience is described as more cumbersome, slower, and lacking parity with desktop views and interactions.[^1_12][^1_13]

AI does not fix these structural issues, and for some users it exacerbates performance problems.

### 1.8 Privacy and data‑use concerns

While Notion provides documentation on data handling, reviewers still flag **generic privacy concerns**:

- Any AI feature that processes user content raises worries for **businesses with sensitive documents**, especially when data may transit external models.[^1_17][^1_5]
- Organizations subject to strict compliance regimes often hesitate to push confidential content through Notion AI at all, preferring more controllable or on‑prem solutions.[^1_2][^1_4][^1_17]

***

## 2. Google NotebookLM – Most Common Complaints

NotebookLM is widely praised as a **source‑grounded research assistant**, but real‑world use in 2024–2025 exposes several recurring limitations.[^1_18][^1_19][^1_7][^1_8][^1_20]

### 2.1 Context window and “hidden” coverage limits

Although Google documents headline limits (e.g., 500k words per source, 200MB per upload), users have discovered **practical context limitations**:[^1_19]

- NotebookLM only processes a slice of very long documents within the model’s **context window**, meaning **not all pages or sections are actually “visible” to the AI** during a given interaction.[^1_6]
- Users have reported cases where the system silently works with only certain page ranges within a file, leading to **missed information and non‑transparent truncation**.[^1_6]
- This undermines trust for use cases like research and legal review, where **“did it actually read everything?”** matters deeply.[^1_21][^1_6]


### 2.2 Strict quotas and feature limits

Complaints about **hard product limits** are common:

- Free tier limits such as **100 notebooks, up to 50 sources per notebook, 500k words per source, and daily caps on chat queries and audio generations** are often hit by heavy users.[^1_19]
- NotebookLM Plus exists to raise these limits (e.g., up to 500 notebooks and 300 sources each, and higher daily quotas), but this turns scalability into a **paywall issue**.[^1_22][^1_18][^1_19]
- Users doing serious academic or enterprise research feel constrained by **daily chat/audio caps** and per‑source size limits.[^1_18][^1_19]


### 2.3 Rigid notebook structure and no cross‑notebook knowledge

A major structural complaint: **each notebook is an island**.

- Reviews repeatedly note that you **cannot connect notebooks to each other**; there is no global graph of knowledge, just siloed projects.[^1_7][^1_8]
- Within a notebook, customization is limited; you can **not deeply structure or interlink notes** the way you can in a tool like Notion or Obsidian.[^1_8][^1_7]
- Result: NotebookLM is widely seen as a **supplementary research assistant**, not a primary “second brain” or central note system.[^1_7][^1_8]


### 2.4 Limited editing and authoring features

NotebookLM is strong at reading and summarizing sources, but weak as a **place to actually write and refine documents**:

- Reviews highlight **limited editing features** and weak long‑form writing support compared to full note‑taking or document apps.[^1_8][^1_7]
- It excels at **summaries, FAQs, and Q\&A** over uploaded material, but is often described as lacking the tools to manage and polish long outputs as part of an ongoing writing workflow.[^1_7][^1_8]


### 2.5 Hallucinations and fabricated details (despite being “grounded”)

Google markets NotebookLM as source‑grounded and less hallucination‑prone, but real‑world tests still show hallucinations:

- Users and educators report cases where NotebookLM **fabricates quotes and concepts that do not appear anywhere in the sources**.[^1_20][^1_23][^1_24]
    - Example: generating a polished quote about broadband and digital access that simply did not exist in the uploaded document.[^1_23]
    - Making up expansions for acronyms that were never defined in the source text.[^1_23]
- Others note that while hallucination rates seem **lower than generic chatbots**, they are **not zero**, especially when prompts push beyond what is clearly stated in the documents.[^1_24][^1_20][^1_8]

This forces serious users to **manually verify citations and text**, reducing the promised time savings.

### 2.6 File‑type and layout limitations

Several weaknesses show up around **non‑trivial documents and formats**:

- Difficulty handling **complex PDF layouts** such as scripts, heavily indented or multi‑column text.[^1_8]
- Lack of support for **CSV and Excel**, which limits use for data‑heavy workflows.[^1_8]
- Similar to other chat‑with‑PDF tools, complex formatting, tables, and certain encodings can produce **broken or partial extractions**.[^1_25][^1_26][^1_8]


### 2.7 Language and feature availability limits

- Some NotebookLM features (e.g., certain interactive audio capabilities) have been **English‑only and/or region‑restricted**, annoying non‑English users.[^1_27][^1_18]
- Users in some regions report features being silently disabled or hard‑limited (e.g., time‑limited audio overviews) without clear explanation.[^1_27]


### 2.8 Perceived reliability, “gimmickiness,” and privacy comfort

User sentiment is mixed:

- Some find NotebookLM **“gimmicky” or only “so‑so” in terms of trustworthy results**, especially compared to other research assistants.[^1_28][^1_20]
- Others find it valuable but only **if they are not very privacy‑sensitive**, since it runs on Google infrastructure and is tightly coupled to Google Drive.[^1_28]
- While Google emphasizes that data is not shared externally, **privacy‑conscious users and regulated organizations** still hesitate to push confidential or proprietary corpora into it.[^1_10][^1_29][^1_19]

***

## 3. Other Document‑Based AI Tools – Cross‑Cutting Complaints

This includes AI‑augmented note apps (Mem, Obsidian AI, Tana, Evernote AI, etc.), AI note‑taking recorders (Otter, Fireflies, Bliro, etc.), and “chat with PDF / knowledge‑base” tools (ChatPDF, ChatwithPDF, RAG apps).

### 3.1 Hallucinations, mishearing, and low‑quality outputs

Across tools, **hallucinations and low‑signal output** are one of the most common complaints:

- AI note‑taking apps are reported to **invent “action items” or details** that were never said (e.g., summarizing small talk about politics as “schedule a meeting with the Prime Minister”).[^1_3]
- Users note that transcribers **mishear audio** and “fill in the blanks” instead of marking content as inaudible, embedding incorrect statements into meeting records.[^1_3]
- Chat‑with‑PDF tools often **misinterpret technical terms, tables, or statistics** and sometimes answer with nonsense, especially in specialized legal or research documents.[^1_9][^1_26][^1_25]
- Even source‑grounded systems like NotebookLM **still hallucinate** when pushed beyond the explicit text.[^1_20][^1_24][^1_23][^1_8]

This erodes trust, especially in high‑stakes domains like law, finance, and academic research.

### 3.2 Context window and scale limitations

Most document‑based AI tools run into **hard context limits** and scaling issues:

- Long documents must be chunked, and tools often **cannot reason over an entire large file at once**, leading to missed references or contradictions.[^1_9][^1_21][^1_6]
- RAG‑style systems suffer from **chunking and retrieval issues**: relevant sections may be omitted, context windows overflow, and performance actually degrades when too much text is stuffed into the prompt.[^1_30][^1_31][^1_21]
- Many consumer tools impose strict limits on **file size, page count, and number of uploads per day or per month**, which users frequently hit (e.g. ChatwithPDF losing accuracy after ~10 pages; ChatPDF capping pages and daily uploads).[^1_32][^1_25][^1_9]

Users often only discover these limits after experiencing **mysterious omissions or truncated coverage**.

### 3.3 Structural and organizational constraints

Ironically, tools meant to help with knowledge management often impose **rigid or opaque structures**:

- **Mem AI**:
    - Complaints that it **pushes AI auto‑organization while offering weak core editing**, making basic note‑taking feel bad.[^1_33]
    - Users who prefer explicit folders/tags feel frustrated that Mem encourages **“just dump it in and let AI sort it,”** which does not work for everyone.[^1_34][^1_33]
    - Reports that development slowed or stagnated, with important bugs or core features not being addressed.[^1_33]
- **Tana**:
    - Steep learning curve due to its everything‑is‑a‑node paradigm; many users struggle to understand and use its power effectively.[^1_35]
    - Poor **long‑form writing support**, missing rich formatting, headings, and quote blocks, forcing users to switch tools for serious writing.[^1_35]
    - **Export and lock‑in issues**: exports mainly in JSON, which many users cannot meaningfully use, leading to fears around **data autonomy and portability**.[^1_36]
- **NotebookLM**:
    - Notebooks are **isolated and cannot be interlinked**, making it unsuitable as a general‑purpose knowledge map.[^1_7][^1_8]

Overall, users often complain that these tools excel at **short‑term summarization and retrieval**, but are bad at **long‑term, structured knowledge management**.

### 3.4 Collaboration and integration gaps

Many document‑centric AI tools are still **single‑user or siloed** in practice:

- **Obsidian AI** is praised for personal vaults but criticized for:
    - Lack of robust **multi‑user collaboration**, access control, or shared AI over a single team vault.[^1_37]
    - AI plugins being confined inside the local vault, with **no integration into business workflows** like ticketing systems, CRMs, or live data sources.[^1_37]
- Several RAG and knowledge‑base tools have weak or brittle **APIs and integrations**, limiting how well they plug into existing enterprise systems.[^1_38][^1_4][^1_39][^1_35]

Teams want “AI over all our docs connected to all our tools”; what they get is often **another silo**.

### 3.5 Export, lock‑in, and data‑portability worries

Especially with younger or closed ecosystems:

- Tools like Tana offering only complex JSON exports create **fear of lock‑in** and worry about what happens if the product shuts down or pricing changes.[^1_36]
- Some chat‑with‑PDF services make it hard to selectively export or delete specific chat histories; users must nuke all conversations at once, which is disruptive.[^1_25]

Users increasingly see **clean export paths (Markdown, OPML, PDFs, CSV)** as a non‑negotiable feature.

### 3.6 Pricing, quotas, and perceived nickel‑and‑diming

There is widespread frustration with **credit systems and opaque limits**:

- Users of some PDF‑chat tools report losing daily credits when uploads fail (e.g., hitting a page limit, then still being charged for an unsuccessful upload).[^1_32][^1_9][^1_25]
- Strict daily caps on uploads or chats (e.g., only a few PDFs per day on free tiers) are seen as disproportionate to actual research workflows.[^1_9][^1_25]
- Subscription models with **no rollover of unused credits** feel unfair to infrequent users.[^1_32][^1_25]

These models clash with the expectation that productivity tools should **scale smoothly with actual usage**.

### 3.7 Privacy, consent, and legal risk

For AI that touches documents, **privacy and compliance** are top concerns:

- Lawsuits such as the class action against Otter.ai allege **recording and using private conversations without proper consent**, raising questions about whether vendors or users bear responsibility for notifying participants.[^1_40]
- Legal and privacy experts warn that AI note‑takers can:
    - Capture **confidential or privileged discussions** that may later be discoverable in litigation or expose trade secrets.[^1_29][^1_40][^1_10][^1_3]
    - Complicate compliance with GDPR/CCPA, especially when vendors reuse data for model training.[^1_40][^1_10]
- Guidance for governments and enterprises emphasizes that generative AI tools often have **limited transparency, unclear training data, and hard‑to‑audit behavior**, which is problematic for sensitive or regulated content.[^1_4][^1_2][^1_17]

Colleagues also react socially: people often **do not want to be recorded by AI** and ask for explicit notification or opt‑outs.[^1_41]

### 3.8 Over‑reliance, bias, and skill erosion

Across knowledge‑management use cases, organizations worry about **over‑delegating thinking to AI**:

- Analysts highlight risks of **over‑reliance on AI‑generated content**, leading to degraded critical thinking and loss of internal expertise.[^1_2][^1_4]
- Training data biases propagate into **skewed or non‑representative answers**, especially in global contexts when models are trained on data from a single region.[^1_4][^1_2]
- Poor data quality in document repositories (“garbage in, garbage out”) leads to AI confidently amplifying outdated or wrong information.[^1_39][^1_38][^1_2]

The net concern: AI can **amplify existing problems in a knowledge base**, not just surface insights.

***

## 4. What This Means If You’re Evaluating These Tools

Across Notion AI, NotebookLM, and other document‑based AI products, the most *consistent* real‑world complaints are:

- **Trust and accuracy are not solved problems.** Even “grounded” tools hallucinate and misinterpret documents; verification remains necessary.[^1_24][^1_20][^1_23][^1_25][^1_9][^1_8]
- **Context and scale limits still bite.** Very large or complex document sets routinely exceed practical context windows and product quotas, forcing workarounds like chunking and selective uploads.[^1_31][^1_21][^1_6][^1_9]
- **Structure and editing still matter.** Many tools excel at summaries but are weak as full‑fledged editors or long‑term knowledge systems, especially when users want strict structure and explicit organization.[^1_35][^1_7][^1_8][^1_16]
- **Integration and collaboration are immature.** AI often lives in yet another silo instead of being a true “brain” across all enterprise systems.[^1_38][^1_39][^1_4][^1_37]
- **Privacy and consent are a major friction point.** Legal, compliance, and human‑factors concerns around AI note‑taking and document analysis are real and growing.[^1_17][^1_10][^1_29][^1_40][^1_3]

When choosing or designing around these tools in 2024–2025, the main practical takeaways are:

- Treat them as **assistants, not authorities**; build workflows that include human review of important outputs.
- Be explicit about **scope**: are you buying a research assistant, a document chat front‑end, or a full knowledge base? Most tools are good at one, not all three.
- Test them on your **actual document types and scale** (long PDFs, legal contracts, tables, multilingual docs) before committing.
- Clarify **data handling, consent processes, and export options** up front to avoid lock‑in and compliance surprises.
<span style="display:none">[^1_42][^1_43][^1_44][^1_45][^1_46][^1_47][^1_48]</span>

<div align="center">⁂</div>

[^1_1]: https://complexdiscovery.com/expert-details-how-businesses-are-considering-ai-for-document-review/

[^1_2]: https://www.ivanti.com/blog/ai-knowledge-management-pros-cons-and-best-practices

[^1_3]: https://www.mltaikins.com/insights/noteworthy-concerns-discussing-the-risks-of-ai-note-taking-apps/

[^1_4]: https://kmslh.com/blog/ai-in-knowledge-management-pros-and-cons/

[^1_5]: https://ones.com/blog/notion-ai-review-2024-productivity-revolution-or-hype/

[^1_6]: https://www.reddit.com/r/notebooklm/comments/1l2aosy/i_now_understand_notebook_llms_limitations_and/

[^1_7]: https://thebusinessdive.com/notebooklm-review

[^1_8]: https://www.unite.ai/notebooklm-review/

[^1_9]: https://www.theneuron.ai/tools/chatwithpdf

[^1_10]: https://www.bliro.io/en/blog/privacy-concerns-with-ai-note-taking-what-you-need-to-know

[^1_11]: https://www.reddit.com/r/Notion/comments/1p9g7ml/what_happened_to_the_activity_in_the_notion/

[^1_12]: https://www.skillademia.com/blog/notion-review/

[^1_13]: https://www.rosemet.com/pros-and-cons-of-notion/

[^1_14]: https://www.uctoday.com/unified-communications/notion-review-more-than-just-a-note-taking-app/

[^1_15]: https://www.reddit.com/r/Notion/comments/1mk6sb3/notion_is_ruining_itself_and_i_cant_stop_watching/

[^1_16]: https://www.reddit.com/r/Notion/comments/1j1rlxd/notion_ai_and_its_limitations/

[^1_17]: https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/guide-use-generative-ai.html

[^1_18]: https://www.linkedin.com/pulse/googles-notebooklm-goes-pro-ken-yeung-jbw3e

[^1_19]: https://support.google.com/notebooklm/answer/16269187?hl=en

[^1_20]: https://www.reddit.com/r/notebooklm/comments/1fjhf5q/can_notebooklm_deliver_hallucinationfree_answers/

[^1_21]: https://www.spyglassmtg.com/blog/rag-vs.-prompt-stuffing-overcoming-context-window-limits-for-large-information-dense-documents

[^1_22]: https://www.reddit.com/r/notebooklm/

[^1_23]: https://anacanhoto.com/2024/11/11/from-writing-assistant-to-teaching-tool-my-experience-so-far-using-notebooklm/

[^1_24]: https://www.linkedin.com/learning/notebooklm-first-look/identify-hallucinations-and-inaccurate-information

[^1_25]: https://www.pdfgear.com/support/chatpdf-review.htm

[^1_26]: https://langchain.chatwithmywebsite.com/it/learn/chatpdf-review-2024--is-it-worth-the-hype.html

[^1_27]: https://www.reddit.com/r/notebooklm/rising/

[^1_28]: https://www.reddit.com/r/NoteTaking/comments/1dqew8m/have_you_used_notebooklm_from_google_what_are/

[^1_29]: https://www.kitces.com/blog/artificial-intelligence-ai-meeting-notetakers-note-tools-client-communication-accuracy-domentation/

[^1_30]: https://www.ai21.com/knowledge/long-context-window/

[^1_31]: https://towardsdatascience.com/beyond-rag/

[^1_32]: https://aidetectplus.com/blog/chatpdf-review

[^1_33]: https://www.reddit.com/r/PKMS/comments/17zoah6/is_memai_truly_worth_it/

[^1_34]: https://devchandra.com/blog/mem-ai-review/

[^1_35]: https://otio.ai/blog/tana-pkm

[^1_36]: https://eryinote.com/post/1740

[^1_37]: https://www.eesel.ai/blog/obsidian-ai

[^1_38]: https://expediteinformatics.com/document-ai-trends-benefits-and-challenges-in-2024/

[^1_39]: https://document360.com/blog/pros-and-cons-of-custom-knowledge-base/

[^1_40]: https://www.workplaceprivacyreport.com/2025/08/articles/artificial-intelligence/ai-notetaking-tools-under-fire-lessons-from-the-otter-ai-class-action-complaint/

[^1_41]: https://www.reddit.com/r/ArtificialInteligence/comments/1lxndp8/ethics_of_using_ai_notetaking_apps_at_work/

[^1_42]: https://www.youtube.com/watch?v=9f8GFo96LEI

[^1_43]: https://forum.obsidian.md/t/limitations-of-obsidian/88994

[^1_44]: https://www.reddit.com/r/TanaInc/comments/1n842f9/what_are_the_limits_of_ai_in_tana/

[^1_45]: https://www.youtube.com/watch?v=4gwcvHTAVCA

[^1_46]: https://forum.obsidian.md/t/obsidian-is-good-but-has-several-limitations-including-difficulties-with-adding-specific-titles-lack-of-automatic-date-filling-missing-right-click-option-to-create-urls-and-the-inability-to-tag-notes-across-multiple-related-notes/64363

[^1_47]: https://www.fahimai.com/mem-ai

[^1_48]: https://www.geeky-gadgets.com/google-notebooklm-hallucinations-and-accuracy-breakthrough/

